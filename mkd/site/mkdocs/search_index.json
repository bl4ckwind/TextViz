{
    "docs": [
        {
            "location": "/",
            "text": "TextViz v.0.1\n\n\nGet the latest version of TextViz from Github \nTextVizRep\n.\n\n\nTextViz bietet eine einfache M\u00f6glichkeit statistische und semantische Werte von (Korpus-)dokumenten visuell einzusehen. Dabei kommen die Pythonbibliotheken \nNLTK\n und \nGensim\n zur Analyse und \nbokeh.io\n zur Visualisierung zum Einsatz. \n\n\nFeatures\n\n\n\n\nMost common Types in corpus\n\n\nAvarage Token/Sentence Length in corpus\n\n\nLSI with keywords by topic and document contribution\n\n\nSimilarity request between corpus and a custom document\n\n\nSingle word history in corpus documents\n\n\n\n\nGallery",
            "title": "Home"
        },
        {
            "location": "/#textviz-v01",
            "text": "Get the latest version of TextViz from Github  TextVizRep .  TextViz bietet eine einfache M\u00f6glichkeit statistische und semantische Werte von (Korpus-)dokumenten visuell einzusehen. Dabei kommen die Pythonbibliotheken  NLTK  und  Gensim  zur Analyse und  bokeh.io  zur Visualisierung zum Einsatz.",
            "title": "TextViz v.0.1"
        },
        {
            "location": "/#features",
            "text": "Most common Types in corpus  Avarage Token/Sentence Length in corpus  LSI with keywords by topic and document contribution  Similarity request between corpus and a custom document  Single word history in corpus documents",
            "title": "Features"
        },
        {
            "location": "/#gallery",
            "text": "",
            "title": "Gallery"
        },
        {
            "location": "/Documentation/",
            "text": "Main module\n\n\nclass TextVisualizer\n    def __init__(self, path='docs\\\\'):\n        docs = self.docReader(path)\n        self.textTokens = self.tokenizer(docs)\n        self.sentences = self.sentenceizer(docs)\n\n\n\nDie Hauptklasse \nTextVisualizer\n ruft bei Erstellung eines Objekts die Methoden \ndocReder\n, \ntokenizer\n und \nsentenceizer\n auf, um die Verarbeitung der Korpusdokumente anzusto\u00dfen.\n\nParameter\n\n\n\n\npath\n bestimmt die Position der Textdokumente relativ zum Pfad der Klasse. Standard: \ndocs\\\\\n\n\n\n\ntokenizer\n\n\ntokenizer(self, documents)\n\n\n\nDer bei Erstellung eines Objekts aufgerufene \ntokenizer\n \u00f6ffnet jedes Dokument mit \nutf-8\n encoding und tokenisiert es.\n\n\nReturnvalue:\n Geschachtelte Liste mit jedem tokenisierten Dokument\n\n\nsentenceizer\n\n\nsentenceizer(self, documents)\n\n\n\nDer bei Erstellung eines Objekts aufgerufene \nsentenceizer\n \u00f6ffnet jedes Dokument mit \nutf-8\n encoding und spaltet es an Satzgrenzen.\n\n\nReturnvalue:\n Geschachtelte Liste mit allen S\u00e4tzen eines Dokuments\n\n\nmain\n\n\nmain(self)\n\n\n\nDie \nmain\n Methode kann aufgerufen werden, um alle notwendigen Standardmethoden(\ncreateDictionary, createBow, createLsiModel, prepLsiData, docContrLsi, detAvgSentLength, detAvgWordLength, mostCommonTypes, showMainPlots\n) auszuf\u00fchren und den plot anzusto\u00dfen. Resultat sind Grafiken mit den Features:\n\n\n\n\nMost common Types in corpus\n\n\nAvarage Token/Sentence Length in corpus\n\n\nLSI with keywords by topic and document contribution\n\n\n\n\ncreateDictionary\n\n\ncreateDictionary(self, textTokens, excludeMostCommon=True, excludeTypes=[])\n\n\n\nDie Methode erstellt mit Hilfe von \nGensim\n ein Dictionary (mapping zwischen normalisierten Worten und IDs) f\u00fcr den Corpus. \n\nParameter\n\n\n\n\ntextTokens\n ist der R\u00fcckgabewert der Methode \ntokenizer\n\n\nexcludeMostCommon\n gibt an, ob einige der h\u00e4ufigsten W\u00f6rter der englischen Sprache von dem Prozess ausgeschlossen werden sollen, falls sie in den Dokumenten vorkommen. Standard: \nTrue\n \n\n\nexcludeTypes\n ist eine Liste, die individuell bef\u00fcllt werden kann, um bestimmte Types vom Prozess auszuschlie\u00dfen. Standard: \nNull\n\n\n\n\nReturnvalue:\n Dictionary des Korpus\n\n\ncreateBow\n\n\ncreateBow(self, dictionary, textTokens)\n\n\n\nDie Methode erstellt mit Hilfe von \nGensim\n ein bag-of-words (mapping zwischen Wort IDs und Frequenz) f\u00fcr den Corpus. \n\nParameter\n\n\n\n\ntextTokens\n ist der R\u00fcckgabewert der Methode \ntokenizer\n\n\ndictionary\n ist der R\u00fcckgabewert der Methode \ncreateDictionary\n\n\n\n\nReturnvalue:\n Liste von Tuplen(wort_ID, wort_frequenz)\n\n\ncreateLsiModel\n\n\ncreateLsiModel(self, bow, dictionary, df=False)\n\n\n\nDie Methode erstellt mit Hilfe von \nGensim\n ein lsi-model f\u00fcr den Corpus. \n\nParameter\n\n\n\n\nbow\n ist der R\u00fcckgabewert der Methode \ncreateBow\n\n\ndictionary\n ist der R\u00fcckgabewert der Methode \ncreateDictionary\n\n\ndf\n gibt an, ob das bow-model vorher in ein tfidf-model umgewandelt werden soll. Standard: \nFalse\n\n\n\n\nReturnvalue:\n Ein wrapped lsi-model des Korpus mit 3 topics\n\n\ndocContrLsi\n\n\ndocContrLsi(self, lsi)\n\n\n\nDie Methode berechnet den Anteil, den die Korpusdokumente zu den lsi-topics beitragen. \n\nParameter\n\n\n\n\nlsi\n ist ein Vektor erstellt mit dem lsimodel aus dem bow z. B. \nlsimodel[bow]\n \n\n\n\n\nReturnvalue:\n Geschachtelte Liste mit den Werten geordnet nach topic\n\n\ndetAvgSentLength\n\n\ndetAvgSentLength(self, sentences)\n\n\n\nDie Methode ermittelt die durschnittliche Satzl\u00e4nge im Korpus \n\nParameter\n\n\n\n\nsentences\n ist der R\u00fcckgabewert der Methode \nsentenceizer\n \n\n\n\n\nReturnvalue:\n Tupel(Satzl\u00e4nge in Zeichen, Satzl\u00e4nge in Worten)\n\n\ndetAvgWordLength\n\n\ndetAvgWordLength(self, textTokens)\n\n\n\nDie Methode ermittelt die durschnittliche Wortl\u00e4nge im Korpus \n\nParameter\n\n\n\n\ntextTokens\n ist der R\u00fcckgabewert der Methode \ntokeneizer\n \n\n\n\n\nReturnvalue:\n Wortl\u00e4nge (Int)\n\n\nmostCommonTypes\n\n\nmostCommonTypes(self, dictionary, bow, excludeTypes=[], n=30)\n\n\n\nDie Methode ermittelt die h\u00e4ufigsten W\u00f6rter im Korpus \n\nParameter\n\n\n\n\ndictionary\n ist der R\u00fcckgabewert der Methode \ncreateDictionary\n\n\nbow\n ist der R\u00fcckgabewert der Methode \ncreateBow\n\n\nexcludeTypes\n ist eine Liste, die individuell bef\u00fcllt werden kann, um bestimmte Types vom Prozess auszuschlie\u00dfen. Standard: \nNull\n\n\nn\n gibt die Anzahl der zu ermittelnden W\u00f6rter an. Standard: \n30\n\n\n\n\nReturnvalue:\n Tupel(Liste[W\u00f6rter], Liste[Frequenz])\n\n\nprepLsiData\n\n\nprepLsiData(self, lsimodel)\n\n\n\nDie Methode bereitet die topics des lsi-models zu Darstellung vor\n\nParameter\n\n\n\n\nlsimodel\n ist der R\u00fcckgabewert der Methode \ncreateLsiModel\n\n\n\n\nReturnvalue:\n Geschachtelte Liste [[topic1], [topic2], [topic3]]\n\n\nshowMainPlots\n\n\nshowMainPlots(self, data_MCT, data_avg, data_lsi, data_contr)\n\n\n\nDie Methode bereitet alle gewonnen Daten zu Darstellung vor und zeigt den Plot.\n\nParameter\n\n\n\n\ndata_MCT\n ist der R\u00fcckgabewert der Methode \nmostCommonTypes\n\n\ndata_avg\n ist der R\u00fcckgabewert der Methoden  \navgSentLength + avgWordLength\n\n\n\n\n\n\ndata_lsi\n ist der R\u00fcckgabewert der Methode \nprepLsiData\n\n\n\n\n\n\n\n\n\n\ndata_contr\n ist der R\u00fcckgabewert der Methode \ndocContrLsi\n\n\n\n\n\n\n\n\nOther features\n\n\nsimilarityReq\n\n\nsimilarityReq(self, document='compare\\\\')\n\n\n\nDie Methode macht mit Hilfe von \nGensim\n einen \u00c4hnlichkeitsvergelich zwischen den Korpusdokumenten und einem zus\u00e4tzlichen Dokument.\n\nParameter\n\n\n\n\ndocument\n gibt die Position des zus\u00e4tzlichen Dokuments relativ zum Projektordner an. Standard: \ncompare\\\\\n\n\n\n\nReturnvalue:\n Tupel(Liste[Korpusdokumentnummer], Liste[\u00c4hnlichkeit in Prozent])\n\n\nshowSimPlot\n\n\nshowSimPlot(self, data_sims)\n\n\n\nPlottet die Daten eines similarity requests.\n\nParameter\n\n\n\n\ndata_sim\n ist der R\u00fcckgabewert der Methode \nsimilarityReq\n\n\n\n\nwordHistory\n\n\nwordHistory(self, typ, granularity)\n\n\n\nDie Methode zeigt den \"zeitlichen\" Verlauf eines Wortes in den Korpusdokumenten auf. \n\nParameter\n\n\n\n\ntyp\n bestimmt das aufzuzeichnende Wort\n\n\ngranularity\n bestimmt wie viele W\u00f6rter eines Dokuments zu einem x-Achsenabschnitt zusammengefasst werden sollen\n\n\n\n\nReturnvalue:\n Tupel(Liste[Abschnitt], Liste[Wortvorkommen], Wort)\n\n\nshowHistPlot\n\n\nshowHistPlot(self, data_hist)\n\n\n\nPlottet die Daten einer word history.\n\nParameter\n\n\n\n\ndata_hist\n ist der R\u00fcckgabewert der Methode \nwordHistory\n\n\n\n\nPlot\n\n\nDas Plot-Modul arbeitet im Hintergund und allein mit \nBokeh\n-Funktionen  und ist das R\u00fcckgrat des TextViz. Es werden Bar-, Pie- und Linecharts verwendet, um den jeweligen Aufgaben visuell gerecht zu werden.",
            "title": "Documentation"
        },
        {
            "location": "/Documentation/#main-module",
            "text": "class TextVisualizer\n    def __init__(self, path='docs\\\\'):\n        docs = self.docReader(path)\n        self.textTokens = self.tokenizer(docs)\n        self.sentences = self.sentenceizer(docs)  Die Hauptklasse  TextVisualizer  ruft bei Erstellung eines Objekts die Methoden  docReder ,  tokenizer  und  sentenceizer  auf, um die Verarbeitung der Korpusdokumente anzusto\u00dfen. Parameter   path  bestimmt die Position der Textdokumente relativ zum Pfad der Klasse. Standard:  docs\\\\",
            "title": "Main module"
        },
        {
            "location": "/Documentation/#tokenizer",
            "text": "tokenizer(self, documents)  Der bei Erstellung eines Objekts aufgerufene  tokenizer  \u00f6ffnet jedes Dokument mit  utf-8  encoding und tokenisiert es.  Returnvalue:  Geschachtelte Liste mit jedem tokenisierten Dokument",
            "title": "tokenizer"
        },
        {
            "location": "/Documentation/#sentenceizer",
            "text": "sentenceizer(self, documents)  Der bei Erstellung eines Objekts aufgerufene  sentenceizer  \u00f6ffnet jedes Dokument mit  utf-8  encoding und spaltet es an Satzgrenzen.  Returnvalue:  Geschachtelte Liste mit allen S\u00e4tzen eines Dokuments",
            "title": "sentenceizer"
        },
        {
            "location": "/Documentation/#main",
            "text": "main(self)  Die  main  Methode kann aufgerufen werden, um alle notwendigen Standardmethoden( createDictionary, createBow, createLsiModel, prepLsiData, docContrLsi, detAvgSentLength, detAvgWordLength, mostCommonTypes, showMainPlots ) auszuf\u00fchren und den plot anzusto\u00dfen. Resultat sind Grafiken mit den Features:   Most common Types in corpus  Avarage Token/Sentence Length in corpus  LSI with keywords by topic and document contribution",
            "title": "main"
        },
        {
            "location": "/Documentation/#createdictionary",
            "text": "createDictionary(self, textTokens, excludeMostCommon=True, excludeTypes=[])  Die Methode erstellt mit Hilfe von  Gensim  ein Dictionary (mapping zwischen normalisierten Worten und IDs) f\u00fcr den Corpus.  Parameter   textTokens  ist der R\u00fcckgabewert der Methode  tokenizer  excludeMostCommon  gibt an, ob einige der h\u00e4ufigsten W\u00f6rter der englischen Sprache von dem Prozess ausgeschlossen werden sollen, falls sie in den Dokumenten vorkommen. Standard:  True    excludeTypes  ist eine Liste, die individuell bef\u00fcllt werden kann, um bestimmte Types vom Prozess auszuschlie\u00dfen. Standard:  Null   Returnvalue:  Dictionary des Korpus",
            "title": "createDictionary"
        },
        {
            "location": "/Documentation/#createbow",
            "text": "createBow(self, dictionary, textTokens)  Die Methode erstellt mit Hilfe von  Gensim  ein bag-of-words (mapping zwischen Wort IDs und Frequenz) f\u00fcr den Corpus.  Parameter   textTokens  ist der R\u00fcckgabewert der Methode  tokenizer  dictionary  ist der R\u00fcckgabewert der Methode  createDictionary   Returnvalue:  Liste von Tuplen(wort_ID, wort_frequenz)",
            "title": "createBow"
        },
        {
            "location": "/Documentation/#createlsimodel",
            "text": "createLsiModel(self, bow, dictionary, df=False)  Die Methode erstellt mit Hilfe von  Gensim  ein lsi-model f\u00fcr den Corpus.  Parameter   bow  ist der R\u00fcckgabewert der Methode  createBow  dictionary  ist der R\u00fcckgabewert der Methode  createDictionary  df  gibt an, ob das bow-model vorher in ein tfidf-model umgewandelt werden soll. Standard:  False   Returnvalue:  Ein wrapped lsi-model des Korpus mit 3 topics",
            "title": "createLsiModel"
        },
        {
            "location": "/Documentation/#doccontrlsi",
            "text": "docContrLsi(self, lsi)  Die Methode berechnet den Anteil, den die Korpusdokumente zu den lsi-topics beitragen.  Parameter   lsi  ist ein Vektor erstellt mit dem lsimodel aus dem bow z. B.  lsimodel[bow]     Returnvalue:  Geschachtelte Liste mit den Werten geordnet nach topic",
            "title": "docContrLsi"
        },
        {
            "location": "/Documentation/#detavgsentlength",
            "text": "detAvgSentLength(self, sentences)  Die Methode ermittelt die durschnittliche Satzl\u00e4nge im Korpus  Parameter   sentences  ist der R\u00fcckgabewert der Methode  sentenceizer     Returnvalue:  Tupel(Satzl\u00e4nge in Zeichen, Satzl\u00e4nge in Worten)",
            "title": "detAvgSentLength"
        },
        {
            "location": "/Documentation/#detavgwordlength",
            "text": "detAvgWordLength(self, textTokens)  Die Methode ermittelt die durschnittliche Wortl\u00e4nge im Korpus  Parameter   textTokens  ist der R\u00fcckgabewert der Methode  tokeneizer     Returnvalue:  Wortl\u00e4nge (Int)",
            "title": "detAvgWordLength"
        },
        {
            "location": "/Documentation/#mostcommontypes",
            "text": "mostCommonTypes(self, dictionary, bow, excludeTypes=[], n=30)  Die Methode ermittelt die h\u00e4ufigsten W\u00f6rter im Korpus  Parameter   dictionary  ist der R\u00fcckgabewert der Methode  createDictionary  bow  ist der R\u00fcckgabewert der Methode  createBow  excludeTypes  ist eine Liste, die individuell bef\u00fcllt werden kann, um bestimmte Types vom Prozess auszuschlie\u00dfen. Standard:  Null  n  gibt die Anzahl der zu ermittelnden W\u00f6rter an. Standard:  30   Returnvalue:  Tupel(Liste[W\u00f6rter], Liste[Frequenz])",
            "title": "mostCommonTypes"
        },
        {
            "location": "/Documentation/#preplsidata",
            "text": "prepLsiData(self, lsimodel)  Die Methode bereitet die topics des lsi-models zu Darstellung vor Parameter   lsimodel  ist der R\u00fcckgabewert der Methode  createLsiModel   Returnvalue:  Geschachtelte Liste [[topic1], [topic2], [topic3]]",
            "title": "prepLsiData"
        },
        {
            "location": "/Documentation/#showmainplots",
            "text": "showMainPlots(self, data_MCT, data_avg, data_lsi, data_contr)  Die Methode bereitet alle gewonnen Daten zu Darstellung vor und zeigt den Plot. Parameter   data_MCT  ist der R\u00fcckgabewert der Methode  mostCommonTypes  data_avg  ist der R\u00fcckgabewert der Methoden   avgSentLength + avgWordLength    data_lsi  ist der R\u00fcckgabewert der Methode  prepLsiData      data_contr  ist der R\u00fcckgabewert der Methode  docContrLsi",
            "title": "showMainPlots"
        },
        {
            "location": "/Documentation/#other-features",
            "text": "",
            "title": "Other features"
        },
        {
            "location": "/Documentation/#similarityreq",
            "text": "similarityReq(self, document='compare\\\\')  Die Methode macht mit Hilfe von  Gensim  einen \u00c4hnlichkeitsvergelich zwischen den Korpusdokumenten und einem zus\u00e4tzlichen Dokument. Parameter   document  gibt die Position des zus\u00e4tzlichen Dokuments relativ zum Projektordner an. Standard:  compare\\\\   Returnvalue:  Tupel(Liste[Korpusdokumentnummer], Liste[\u00c4hnlichkeit in Prozent])",
            "title": "similarityReq"
        },
        {
            "location": "/Documentation/#showsimplot",
            "text": "showSimPlot(self, data_sims)  Plottet die Daten eines similarity requests. Parameter   data_sim  ist der R\u00fcckgabewert der Methode  similarityReq",
            "title": "showSimPlot"
        },
        {
            "location": "/Documentation/#wordhistory",
            "text": "wordHistory(self, typ, granularity)  Die Methode zeigt den \"zeitlichen\" Verlauf eines Wortes in den Korpusdokumenten auf.  Parameter   typ  bestimmt das aufzuzeichnende Wort  granularity  bestimmt wie viele W\u00f6rter eines Dokuments zu einem x-Achsenabschnitt zusammengefasst werden sollen   Returnvalue:  Tupel(Liste[Abschnitt], Liste[Wortvorkommen], Wort)",
            "title": "wordHistory"
        },
        {
            "location": "/Documentation/#showhistplot",
            "text": "showHistPlot(self, data_hist)  Plottet die Daten einer word history. Parameter   data_hist  ist der R\u00fcckgabewert der Methode  wordHistory",
            "title": "showHistPlot"
        },
        {
            "location": "/Documentation/#plot",
            "text": "Das Plot-Modul arbeitet im Hintergund und allein mit  Bokeh -Funktionen  und ist das R\u00fcckgrat des TextViz. Es werden Bar-, Pie- und Linecharts verwendet, um den jeweligen Aufgaben visuell gerecht zu werden.",
            "title": "Plot"
        }
    ]
}